{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab1f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbc333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f23e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78aeab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chamodi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3828e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chamodi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c285bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d849173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c4e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function for remove the punctuation in the documents\n",
    "def removePunctuation(file):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in file:\n",
    "        if char not in  punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044b5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open encoding = \"UTF-8\"\n",
    "#read() file is readed\n",
    "#lower() turned all the words in to lower case\n",
    "#The strip() method removes any leading (spaces at the beginning) and trailing (spaces at the end) characters (space is the default leading character to remove)\n",
    "#split()splits a string into a list. \n",
    "doc1 = open(\"1\", \"r\", encoding=\"utf-8\").read().lower().strip().split(\" \")\n",
    "doc2 = open(\"2\", \"r\", encoding=\"utf-8\").read().lower().strip().split(\" \")\n",
    "doc3 = open(\"3\", \"r\", encoding=\"utf-8\").read().lower().strip().split(\" \")\n",
    "doc4 = open(\"4\", \"r\", encoding=\"utf-8\").read().lower().strip().split(\" \")\n",
    "doc5 = open(\"5\", \"r\", encoding=\"utf-8\").read().lower().strip().split(\" \")\n",
    "#open the query file\n",
    "query = open(\"Query\", \"r\", encoding=\"utf-8\").read().lower().strip().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225be380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['our', 'research', 'examines', 'a', 'predictive', 'machine', 'learning', 'approach', 'for', 'financial', 'news', 'articles', 'analysis', 'using', 'several', 'different', 'textual', 'representations:', 'bag', 'of', 'words,', 'noun', 'phrases,', 'and', 'named', 'entities.', 'through', 'this', 'approach,', 'we', 'investigated', '9,211', 'financial', 'news', 'articles', 'and', '10,259,042', 'stock', 'quotes', 'covering', 'the', 's&p', '500', 'stocks', 'during', 'a', 'five', 'week', 'period.', 'we', 'applied', 'our', 'analysis', 'to', 'estimate', 'a', 'discrete', 'stock', 'price', 'twenty', 'minutes', 'after', 'a', 'news', 'article', 'was', 'released.', 'using', 'a', 'support', 'vector', 'machine', '(svm)', 'derivative', 'specially', 'tailored', 'for', 'discrete', 'numeric', 'prediction', 'and', 'models', 'containing', 'different', 'stock-specific', 'variables,', 'we', 'show', 'that', 'the', 'model', 'containing', 'both', 'article', 'terms', 'and', 'stock', 'price', 'at', 'the', 'time', 'of', 'article', 'release', 'had', 'the', 'best', 'performance', 'in', 'closeness', 'to', 'the', 'actual', 'future', 'stock', 'price', '(mse', '0.04261),', 'the', 'same', 'direction', 'of', 'price', 'movement', 'as', 'the', 'future', 'price', '(57.1%', 'directional', 'accuracy)', 'and', 'the', 'highest', 'return', 'using', 'a', 'simulated', 'trading', 'engine', '(2.06%', 'return).', 'we', 'further', 'investigated', 'the', 'different', 'textual', 'representations', 'and', 'found', 'that', 'a', 'proper', 'noun', 'scheme', 'performs', 'better', 'than', 'the', 'de', 'facto', 'standard', 'of', 'bag', 'of', 'words', 'in', 'all', 'three', 'metrics.'] ['we', 'trained', 'a', 'large,', 'deep', 'convolutional', 'neural', 'network', 'to', 'classify', 'the', '1.2', 'million', 'high-resolution', 'images', 'in', 'the', 'imagenet', 'lsvrc-2010', 'contest', 'into', 'the', '1000', 'different', 'classes.', 'on', 'the', 'test', 'data,', 'we', 'achieved', 'top-1', 'and', 'top-5', 'error', 'rates', 'of', '37.5%', 'and', '17.0%', 'which', 'is', 'considerably', 'better', 'than', 'the', 'previous', 'state-of-the-art.', 'the', 'neural', 'network,', 'which', 'has', '60', 'million', 'parameters', 'and', '650,000', 'neurons,', 'consists', 'of', 'five', 'convolutional', 'layers,', 'some', 'of', 'which', 'are', 'followed', 'by', 'max-pooling', 'layers,', 'and', 'three', 'fully-connected', 'layers', 'with', 'a', 'final', '1000-way', 'softmax.', 'to', 'make', 'training', 'faster,', 'we', 'used', 'non-saturating', 'neurons', 'and', 'a', 'very', 'efficient', 'gpu', 'implementation', 'of', 'the', 'convolution', 'operation.', 'to', 'reduce', 'overfitting', 'in', 'the', 'fully-connected', 'layers', 'we', 'employed', 'a', 'recently-developed', 'regularization', 'method', 'called', '“dropout”', 'that', 'proved', 'to', 'be', 'very', 'effective.', 'we', 'also', 'entered', 'a', 'variant', 'of', 'this', 'model', 'in', 'the', 'ilsvrc-2012', 'competition', 'and', 'achieved', 'a', 'winning', 'top-5', 'test', 'error', 'rate', 'of', '15.3%,', 'compared', 'to', '26.2%', 'achieved', 'by', 'the', 'second-best', 'entry.'] ['a', 'purely', 'peer-to-peer', 'version', 'of', 'electronic', 'cash', 'would', 'allow', 'online', 'payments', 'to', 'be', 'sent', 'directly', 'from', 'one', 'party', 'to', 'another', 'without', 'going', 'through', 'a', 'financial', 'institution.', 'digital', 'signatures', 'provide', 'part', 'of', 'the', 'solution,', 'but', 'the', 'main', 'benefits', 'are', 'lost', 'if', 'a', 'trusted', 'third', 'party', 'is', 'still', 'required', 'to', 'prevent', 'double-spending.', 'we', 'propose', 'a', 'solution', 'to', 'the', 'double-spending', 'problem', 'using', 'a', 'peer-to-peer', 'network.', 'the', 'network', 'timestamps', 'transactions', 'by', 'hashing', 'them', 'into', 'an', 'ongoing', 'chain', 'of', 'hash-based', 'proof-of-work,', 'forming', 'a', 'record', 'that', 'cannot', 'be', 'changed', 'without', 'redoing', 'the', 'proof-of-work.', 'the', 'longest', 'chain', 'not', 'only', 'serves', 'as', 'proof', 'of', 'the', 'sequence', 'of', 'events', 'witnessed,', 'but', 'proof', 'that', 'it', 'came', 'from', 'the', 'largest', 'pool', 'of', 'cpu', 'power.', 'as', 'long', 'as', 'a', 'majority', 'of', 'cpu', 'power', 'is', 'controlled', 'by', 'nodes', 'that', 'are', 'not', 'cooperating', 'to', 'attack', 'the', 'network,', 'they’ll', 'generate', 'the', 'longest', 'chain', 'and', 'outpace', 'attackers.', 'the', 'network', 'itself', 'requires', 'minimal', 'structure.', 'messages', 'are', 'broadcast', 'on', 'a', 'best', 'effort', 'basis,', 'and', 'nodes', 'can', 'leave', 'and', 'rejoin', 'the', 'network', 'at', 'will,', 'accepting', 'the', 'longest', 'proof-of-work', 'chain', 'as', 'proof', 'of', 'what', 'happened', 'while', 'they', 'were', 'gone.'] ['we', 'identified', 'seasonal', 'human', 'coronaviruses,', 'influenza', 'viruses', 'and', 'rhinoviruses', 'in', 'exhaled', 'breath', 'and', 'coughs', 'of', 'children', 'and', 'adults', 'with', 'acute', 'respiratory', 'illness.', 'surgical', 'face', 'masks', 'significantly', 'reduced', 'detection', 'of', 'influenza', 'virus', 'rna', 'in', 'respiratory', 'droplets', 'and', 'coronavirus', 'rna', 'in', 'aerosols,', 'with', 'a', 'trend', 'toward', 'reduced', 'detection', 'of', 'coronavirus', 'rna', 'in', 'respiratory', 'droplets.', 'our', 'results', 'indicate', 'that', 'surgical', 'face', 'masks', 'could', 'prevent', 'transmission', 'of', 'human', 'coronaviruses', 'and', 'influenza', 'viruses', 'from', 'symptomatic', 'individuals.'] ['quantum', 'computers', 'promise', 'to', 'perform', 'certain', 'tasks', 'that', 'are', 'believed', 'to', 'be', 'intractable', 'to', 'classical', 'computers.', 'boson', 'sampling', 'is', 'such', 'a', 'task', 'and', 'is', 'considered', 'a', 'strong', 'candidate', 'to', 'demonstrate', 'the', 'quantum', 'computational', 'advantage.', 'we', 'performed', 'gaussian', 'boson', 'sampling', 'by', 'sending', '50', 'indistinguishable', 'single-mode', 'squeezed', 'states', 'into', 'a', '100-mode', 'ultralow-loss', 'interferometer', 'with', 'full', 'connectivity', 'and', 'random', 'matrix—the', 'whole', 'optical', 'setup', 'is', 'phase-locked—and', 'sampling', 'the', 'output', 'using', '100', 'high-efficiency', 'single-photon', 'detectors.', 'the', 'obtained', 'samples', 'were', 'validated', 'against', 'plausible', 'hypotheses', 'exploiting', 'thermal', 'states,', 'distinguishable', 'photons,', 'and', 'uniform', 'distribution.', 'the', 'photonic', 'quantum', 'computer,', 'jiuzhang,', 'generates', 'up', 'to', '76', 'output', 'photon', 'clicks,', 'which', 'yields', 'an', 'output', 'state-space', 'dimension', 'of', '1030', 'and', 'a', 'sampling', 'rate', 'that', 'is', 'faster', 'than', 'using', 'the', 'state-of-the-art', 'simulation', 'strategy', 'and', 'supercomputers', 'by', 'a', 'factor', 'of', '~1014.']\n"
     ]
    }
   ],
   "source": [
    "#print the split words\n",
    "print (doc1, doc2, doc3, doc4, doc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce603147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trained', 'deep', 'convolutional', 'neural', 'network,', 'which', 'has', '60', 'million', 'parameters', 'and', '650,000', 'neurons,', 'consists', 'of', 'five', 'convolutional', 'layers,', 'some', 'of', 'which', 'are', 'followed', 'by', 'max-pooling', 'layers,', 'and', 'three', 'fully-connected', 'layers', 'with', 'a', 'final', '1000-way', 'softmax', 'to', 'classify', 'the', '1.2', 'million', 'high-resolution', 'images', 'in', 'the', 'imagenet', 'lsvrc-2010', 'contest', 'into', 'the', '1000', 'different', 'classes.']\n"
     ]
    }
   ],
   "source": [
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55977adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the stop word from the document using the NLTK\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760723e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered split words\n",
    "doc1_filtered_sentence = [word for word in doc1 if not word in stop_words]\n",
    "doc2_filtered_sentence = [word for word in doc2 if not word in stop_words]\n",
    "doc3_filtered_sentence = [word for word in doc3 if not word in stop_words]\n",
    "doc4_filtered_sentence = [word for word in doc4 if not word in stop_words]\n",
    "doc5_filtered_sentence = [word for word in doc5 if not word in stop_words]\n",
    "#query filtered split words\n",
    "query_filtered_sentence = [word for word in query if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521f3470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['research', 'examines', 'predictive', 'machine', 'learning', 'approach', 'financial', 'news', 'articles', 'analysis', 'using', 'several', 'different', 'textual', 'representations:', 'bag', 'words,', 'noun', 'phrases,', 'named', 'entities.', 'approach,', 'investigated', '9,211', 'financial', 'news', 'articles', '10,259,042', 'stock', 'quotes', 'covering', 's&p', '500', 'stocks', 'five', 'week', 'period.', 'applied', 'analysis', 'estimate', 'discrete', 'stock', 'price', 'twenty', 'minutes', 'news', 'article', 'released.', 'using', 'support', 'vector', 'machine', '(svm)', 'derivative', 'specially', 'tailored', 'discrete', 'numeric', 'prediction', 'models', 'containing', 'different', 'stock-specific', 'variables,', 'show', 'model', 'containing', 'article', 'terms', 'stock', 'price', 'time', 'article', 'release', 'best', 'performance', 'closeness', 'actual', 'future', 'stock', 'price', '(mse', '0.04261),', 'direction', 'price', 'movement', 'future', 'price', '(57.1%', 'directional', 'accuracy)', 'highest', 'return', 'using', 'simulated', 'trading', 'engine', '(2.06%', 'return).', 'investigated', 'different', 'textual', 'representations', 'found', 'proper', 'noun', 'scheme', 'performs', 'better', 'de', 'facto', 'standard', 'bag', 'words', 'three', 'metrics.'] ['trained', 'large,', 'deep', 'convolutional', 'neural', 'network', 'classify', '1.2', 'million', 'high-resolution', 'images', 'imagenet', 'lsvrc-2010', 'contest', '1000', 'different', 'classes.', 'test', 'data,', 'achieved', 'top-1', 'top-5', 'error', 'rates', '37.5%', '17.0%', 'considerably', 'better', 'previous', 'state-of-the-art.', 'neural', 'network,', '60', 'million', 'parameters', '650,000', 'neurons,', 'consists', 'five', 'convolutional', 'layers,', 'followed', 'max-pooling', 'layers,', 'three', 'fully-connected', 'layers', 'final', '1000-way', 'softmax.', 'make', 'training', 'faster,', 'used', 'non-saturating', 'neurons', 'efficient', 'gpu', 'implementation', 'convolution', 'operation.', 'reduce', 'overfitting', 'fully-connected', 'layers', 'employed', 'recently-developed', 'regularization', 'method', 'called', '“dropout”', 'proved', 'effective.', 'also', 'entered', 'variant', 'model', 'ilsvrc-2012', 'competition', 'achieved', 'winning', 'top-5', 'test', 'error', 'rate', '15.3%,', 'compared', '26.2%', 'achieved', 'second-best', 'entry.'] ['purely', 'peer-to-peer', 'version', 'electronic', 'cash', 'would', 'allow', 'online', 'payments', 'sent', 'directly', 'one', 'party', 'another', 'without', 'going', 'financial', 'institution.', 'digital', 'signatures', 'provide', 'part', 'solution,', 'main', 'benefits', 'lost', 'trusted', 'third', 'party', 'still', 'required', 'prevent', 'double-spending.', 'propose', 'solution', 'double-spending', 'problem', 'using', 'peer-to-peer', 'network.', 'network', 'timestamps', 'transactions', 'hashing', 'ongoing', 'chain', 'hash-based', 'proof-of-work,', 'forming', 'record', 'cannot', 'changed', 'without', 'redoing', 'proof-of-work.', 'longest', 'chain', 'serves', 'proof', 'sequence', 'events', 'witnessed,', 'proof', 'came', 'largest', 'pool', 'cpu', 'power.', 'long', 'majority', 'cpu', 'power', 'controlled', 'nodes', 'cooperating', 'attack', 'network,', 'they’ll', 'generate', 'longest', 'chain', 'outpace', 'attackers.', 'network', 'requires', 'minimal', 'structure.', 'messages', 'broadcast', 'best', 'effort', 'basis,', 'nodes', 'leave', 'rejoin', 'network', 'will,', 'accepting', 'longest', 'proof-of-work', 'chain', 'proof', 'happened', 'gone.'] ['identified', 'seasonal', 'human', 'coronaviruses,', 'influenza', 'viruses', 'rhinoviruses', 'exhaled', 'breath', 'coughs', 'children', 'adults', 'acute', 'respiratory', 'illness.', 'surgical', 'face', 'masks', 'significantly', 'reduced', 'detection', 'influenza', 'virus', 'rna', 'respiratory', 'droplets', 'coronavirus', 'rna', 'aerosols,', 'trend', 'toward', 'reduced', 'detection', 'coronavirus', 'rna', 'respiratory', 'droplets.', 'results', 'indicate', 'surgical', 'face', 'masks', 'could', 'prevent', 'transmission', 'human', 'coronaviruses', 'influenza', 'viruses', 'symptomatic', 'individuals.'] ['quantum', 'computers', 'promise', 'perform', 'certain', 'tasks', 'believed', 'intractable', 'classical', 'computers.', 'boson', 'sampling', 'task', 'considered', 'strong', 'candidate', 'demonstrate', 'quantum', 'computational', 'advantage.', 'performed', 'gaussian', 'boson', 'sampling', 'sending', '50', 'indistinguishable', 'single-mode', 'squeezed', 'states', '100-mode', 'ultralow-loss', 'interferometer', 'full', 'connectivity', 'random', 'matrix—the', 'whole', 'optical', 'setup', 'phase-locked—and', 'sampling', 'output', 'using', '100', 'high-efficiency', 'single-photon', 'detectors.', 'obtained', 'samples', 'validated', 'plausible', 'hypotheses', 'exploiting', 'thermal', 'states,', 'distinguishable', 'photons,', 'uniform', 'distribution.', 'photonic', 'quantum', 'computer,', 'jiuzhang,', 'generates', '76', 'output', 'photon', 'clicks,', 'yields', 'output', 'state-space', 'dimension', '1030', 'sampling', 'rate', 'faster', 'using', 'state-of-the-art', 'simulation', 'strategy', 'supercomputers', 'factor', '~1014.']\n"
     ]
    }
   ],
   "source": [
    "print (doc1_filtered_sentence , doc2_filtered_sentence, doc3_filtered_sentence, doc4_filtered_sentence, doc5_filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0384087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trained', 'deep', 'convolutional', 'neural', 'network,', '60', 'million', 'parameters', '650,000', 'neurons,', 'consists', 'five', 'convolutional', 'layers,', 'followed', 'max-pooling', 'layers,', 'three', 'fully-connected', 'layers', 'final', '1000-way', 'softmax', 'classify', '1.2', 'million', 'high-resolution', 'images', 'imagenet', 'lsvrc-2010', 'contest', '1000', 'different', 'classes.']\n"
     ]
    }
   ],
   "source": [
    "print (query_filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1d7d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The union() method returns a set that contains all items from the original set, and all items from the specified set(s).\n",
    "#If an item is present in more than one set, the result will contain only one appearance of this item.\n",
    "wordSet = set(doc1_filtered_sentence).union(set(doc2_filtered_sentence),set(doc3_filtered_sentence),set(doc4_filtered_sentence),set(doc5_filtered_sentence),set(query_filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf224b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(2.06%',\n",
       " '(57.1%',\n",
       " '(mse',\n",
       " '(svm)',\n",
       " '0.04261),',\n",
       " '1.2',\n",
       " '10,259,042',\n",
       " '100',\n",
       " '100-mode',\n",
       " '1000',\n",
       " '1000-way',\n",
       " '1030',\n",
       " '15.3%,',\n",
       " '17.0%',\n",
       " '26.2%',\n",
       " '37.5%',\n",
       " '50',\n",
       " '500',\n",
       " '60',\n",
       " '650,000',\n",
       " '76',\n",
       " '9,211',\n",
       " 'accepting',\n",
       " 'accuracy)',\n",
       " 'achieved',\n",
       " 'actual',\n",
       " 'acute',\n",
       " 'adults',\n",
       " 'advantage.',\n",
       " 'aerosols,',\n",
       " 'allow',\n",
       " 'also',\n",
       " 'analysis',\n",
       " 'another',\n",
       " 'applied',\n",
       " 'approach',\n",
       " 'approach,',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'attack',\n",
       " 'attackers.',\n",
       " 'bag',\n",
       " 'basis,',\n",
       " 'believed',\n",
       " 'benefits',\n",
       " 'best',\n",
       " 'better',\n",
       " 'boson',\n",
       " 'breath',\n",
       " 'broadcast',\n",
       " 'called',\n",
       " 'came',\n",
       " 'candidate',\n",
       " 'cannot',\n",
       " 'cash',\n",
       " 'certain',\n",
       " 'chain',\n",
       " 'changed',\n",
       " 'children',\n",
       " 'classes.',\n",
       " 'classical',\n",
       " 'classify',\n",
       " 'clicks,',\n",
       " 'closeness',\n",
       " 'compared',\n",
       " 'competition',\n",
       " 'computational',\n",
       " 'computer,',\n",
       " 'computers',\n",
       " 'computers.',\n",
       " 'connectivity',\n",
       " 'considerably',\n",
       " 'considered',\n",
       " 'consists',\n",
       " 'containing',\n",
       " 'contest',\n",
       " 'controlled',\n",
       " 'convolution',\n",
       " 'convolutional',\n",
       " 'cooperating',\n",
       " 'coronavirus',\n",
       " 'coronaviruses',\n",
       " 'coronaviruses,',\n",
       " 'coughs',\n",
       " 'could',\n",
       " 'covering',\n",
       " 'cpu',\n",
       " 'data,',\n",
       " 'de',\n",
       " 'deep',\n",
       " 'demonstrate',\n",
       " 'derivative',\n",
       " 'detection',\n",
       " 'detectors.',\n",
       " 'different',\n",
       " 'digital',\n",
       " 'dimension',\n",
       " 'direction',\n",
       " 'directional',\n",
       " 'directly',\n",
       " 'discrete',\n",
       " 'distinguishable',\n",
       " 'distribution.',\n",
       " 'double-spending',\n",
       " 'double-spending.',\n",
       " 'droplets',\n",
       " 'droplets.',\n",
       " 'effective.',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'electronic',\n",
       " 'employed',\n",
       " 'engine',\n",
       " 'entered',\n",
       " 'entities.',\n",
       " 'entry.',\n",
       " 'error',\n",
       " 'estimate',\n",
       " 'events',\n",
       " 'examines',\n",
       " 'exhaled',\n",
       " 'exploiting',\n",
       " 'face',\n",
       " 'facto',\n",
       " 'factor',\n",
       " 'faster',\n",
       " 'faster,',\n",
       " 'final',\n",
       " 'financial',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'forming',\n",
       " 'found',\n",
       " 'full',\n",
       " 'fully-connected',\n",
       " 'future',\n",
       " 'gaussian',\n",
       " 'generate',\n",
       " 'generates',\n",
       " 'going',\n",
       " 'gone.',\n",
       " 'gpu',\n",
       " 'happened',\n",
       " 'hash-based',\n",
       " 'hashing',\n",
       " 'high-efficiency',\n",
       " 'high-resolution',\n",
       " 'highest',\n",
       " 'human',\n",
       " 'hypotheses',\n",
       " 'identified',\n",
       " 'illness.',\n",
       " 'ilsvrc-2012',\n",
       " 'imagenet',\n",
       " 'images',\n",
       " 'implementation',\n",
       " 'indicate',\n",
       " 'indistinguishable',\n",
       " 'individuals.',\n",
       " 'influenza',\n",
       " 'institution.',\n",
       " 'interferometer',\n",
       " 'intractable',\n",
       " 'investigated',\n",
       " 'jiuzhang,',\n",
       " 'large,',\n",
       " 'largest',\n",
       " 'layers',\n",
       " 'layers,',\n",
       " 'learning',\n",
       " 'leave',\n",
       " 'long',\n",
       " 'longest',\n",
       " 'lost',\n",
       " 'lsvrc-2010',\n",
       " 'machine',\n",
       " 'main',\n",
       " 'majority',\n",
       " 'make',\n",
       " 'masks',\n",
       " 'matrix—the',\n",
       " 'max-pooling',\n",
       " 'messages',\n",
       " 'method',\n",
       " 'metrics.',\n",
       " 'million',\n",
       " 'minimal',\n",
       " 'minutes',\n",
       " 'model',\n",
       " 'models',\n",
       " 'movement',\n",
       " 'named',\n",
       " 'network',\n",
       " 'network,',\n",
       " 'network.',\n",
       " 'neural',\n",
       " 'neurons',\n",
       " 'neurons,',\n",
       " 'news',\n",
       " 'nodes',\n",
       " 'non-saturating',\n",
       " 'noun',\n",
       " 'numeric',\n",
       " 'obtained',\n",
       " 'one',\n",
       " 'ongoing',\n",
       " 'online',\n",
       " 'operation.',\n",
       " 'optical',\n",
       " 'outpace',\n",
       " 'output',\n",
       " 'overfitting',\n",
       " 'parameters',\n",
       " 'part',\n",
       " 'party',\n",
       " 'payments',\n",
       " 'peer-to-peer',\n",
       " 'perform',\n",
       " 'performance',\n",
       " 'performed',\n",
       " 'performs',\n",
       " 'period.',\n",
       " 'phase-locked—and',\n",
       " 'photon',\n",
       " 'photonic',\n",
       " 'photons,',\n",
       " 'phrases,',\n",
       " 'plausible',\n",
       " 'pool',\n",
       " 'power',\n",
       " 'power.',\n",
       " 'prediction',\n",
       " 'predictive',\n",
       " 'prevent',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'problem',\n",
       " 'promise',\n",
       " 'proof',\n",
       " 'proof-of-work',\n",
       " 'proof-of-work,',\n",
       " 'proof-of-work.',\n",
       " 'proper',\n",
       " 'propose',\n",
       " 'proved',\n",
       " 'provide',\n",
       " 'purely',\n",
       " 'quantum',\n",
       " 'quotes',\n",
       " 'random',\n",
       " 'rate',\n",
       " 'rates',\n",
       " 'recently-developed',\n",
       " 'record',\n",
       " 'redoing',\n",
       " 'reduce',\n",
       " 'reduced',\n",
       " 'regularization',\n",
       " 'rejoin',\n",
       " 'release',\n",
       " 'released.',\n",
       " 'representations',\n",
       " 'representations:',\n",
       " 'required',\n",
       " 'requires',\n",
       " 'research',\n",
       " 'respiratory',\n",
       " 'results',\n",
       " 'return',\n",
       " 'return).',\n",
       " 'rhinoviruses',\n",
       " 'rna',\n",
       " 's&p',\n",
       " 'samples',\n",
       " 'sampling',\n",
       " 'scheme',\n",
       " 'seasonal',\n",
       " 'second-best',\n",
       " 'sending',\n",
       " 'sent',\n",
       " 'sequence',\n",
       " 'serves',\n",
       " 'setup',\n",
       " 'several',\n",
       " 'show',\n",
       " 'signatures',\n",
       " 'significantly',\n",
       " 'simulated',\n",
       " 'simulation',\n",
       " 'single-mode',\n",
       " 'single-photon',\n",
       " 'softmax',\n",
       " 'softmax.',\n",
       " 'solution',\n",
       " 'solution,',\n",
       " 'specially',\n",
       " 'squeezed',\n",
       " 'standard',\n",
       " 'state-of-the-art',\n",
       " 'state-of-the-art.',\n",
       " 'state-space',\n",
       " 'states',\n",
       " 'states,',\n",
       " 'still',\n",
       " 'stock',\n",
       " 'stock-specific',\n",
       " 'stocks',\n",
       " 'strategy',\n",
       " 'strong',\n",
       " 'structure.',\n",
       " 'supercomputers',\n",
       " 'support',\n",
       " 'surgical',\n",
       " 'symptomatic',\n",
       " 'tailored',\n",
       " 'task',\n",
       " 'tasks',\n",
       " 'terms',\n",
       " 'test',\n",
       " 'textual',\n",
       " 'thermal',\n",
       " 'they’ll',\n",
       " 'third',\n",
       " 'three',\n",
       " 'time',\n",
       " 'timestamps',\n",
       " 'top-1',\n",
       " 'top-5',\n",
       " 'toward',\n",
       " 'trading',\n",
       " 'trained',\n",
       " 'training',\n",
       " 'transactions',\n",
       " 'transmission',\n",
       " 'trend',\n",
       " 'trusted',\n",
       " 'twenty',\n",
       " 'ultralow-loss',\n",
       " 'uniform',\n",
       " 'used',\n",
       " 'using',\n",
       " 'validated',\n",
       " 'variables,',\n",
       " 'variant',\n",
       " 'vector',\n",
       " 'version',\n",
       " 'virus',\n",
       " 'viruses',\n",
       " 'week',\n",
       " 'whole',\n",
       " 'will,',\n",
       " 'winning',\n",
       " 'without',\n",
       " 'witnessed,',\n",
       " 'words',\n",
       " 'words,',\n",
       " 'would',\n",
       " 'yields',\n",
       " '~1014.',\n",
       " '“dropout”'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets view the wordSet created using union fuction with uniqe words of abve 6 sentences\n",
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24f1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create 6 dictionaries to hold the terms(words) in wordSet and the count of those words appear in each and every sentences(documents) considered above\n",
    "#Let's initialise the count of all words to 0 first\n",
    "doc1_wordDict = dict.fromkeys(wordSet, 0) \n",
    "doc2_wordDict = dict.fromkeys(wordSet, 0)\n",
    "doc3_wordDict = dict.fromkeys(wordSet, 0)\n",
    "doc4_wordDict = dict.fromkeys(wordSet, 0)\n",
    "doc5_wordDict = dict.fromkeys(wordSet, 0)\n",
    "query_wordDict = dict.fromkeys(wordSet, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f736bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will get the count of each word appear in each sentence seperately and update the dictionaries respecte to the sentence\n",
    "#eg: for the sentence1 (doc1) we take the count and update doc1_wordDict dictionary.\n",
    "for word in doc1_filtered_sentence:\n",
    "    doc1_wordDict[word]+=1\n",
    "    \n",
    "for word in doc2_filtered_sentence:\n",
    "    doc2_wordDict[word]+=1\n",
    "\n",
    "for word in doc3_filtered_sentence:\n",
    "    doc3_wordDict[word]+=1\n",
    "\n",
    "for word in doc4_filtered_sentence:\n",
    "    doc4_wordDict[word]+=1\n",
    "    \n",
    "for word in doc5_filtered_sentence:\n",
    "    doc5_wordDict[word]+=1\n",
    "    \n",
    "for word in query_filtered_sentence:\n",
    "    query_wordDict[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b657aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 1,\n",
       " 'reduced': 0,\n",
       " 'reduce': 0,\n",
       " 'models': 1,\n",
       " 'week': 1,\n",
       " 'return).': 1,\n",
       " 'effective.': 0,\n",
       " '(mse': 1,\n",
       " 'learning': 1,\n",
       " 'images': 0,\n",
       " 'return': 1,\n",
       " 'computers': 0,\n",
       " 'output': 0,\n",
       " 'detectors.': 0,\n",
       " 'sequence': 0,\n",
       " '10,259,042': 1,\n",
       " 'photon': 0,\n",
       " 'scheme': 1,\n",
       " 'basis,': 0,\n",
       " 'performed': 0,\n",
       " 'photonic': 0,\n",
       " 'parameters': 0,\n",
       " 'contest': 0,\n",
       " 'they’ll': 0,\n",
       " 'identified': 0,\n",
       " 'news': 3,\n",
       " 'phrases,': 1,\n",
       " '“dropout”': 0,\n",
       " 'respiratory': 0,\n",
       " 'future': 2,\n",
       " 'certain': 0,\n",
       " 'record': 0,\n",
       " 'purely': 0,\n",
       " 'layers': 0,\n",
       " 'different': 3,\n",
       " 'computational': 0,\n",
       " 'movement': 1,\n",
       " 'neural': 0,\n",
       " 'previous': 0,\n",
       " 'hash-based': 0,\n",
       " 'significantly': 0,\n",
       " 'candidate': 0,\n",
       " '650,000': 0,\n",
       " 'named': 1,\n",
       " 'called': 0,\n",
       " 'generate': 0,\n",
       " 'coughs': 0,\n",
       " 'virus': 0,\n",
       " 'used': 0,\n",
       " 'strategy': 0,\n",
       " 'accuracy)': 1,\n",
       " 'state-of-the-art': 0,\n",
       " 'trend': 0,\n",
       " 'serves': 0,\n",
       " 'model': 1,\n",
       " 'proof-of-work,': 0,\n",
       " 'results': 0,\n",
       " 'outpace': 0,\n",
       " 'sampling': 0,\n",
       " 'directional': 1,\n",
       " 'discrete': 2,\n",
       " 'breath': 0,\n",
       " 'twenty': 1,\n",
       " 'will,': 0,\n",
       " 'provide': 0,\n",
       " 'rejoin': 0,\n",
       " 'long': 0,\n",
       " 'coronaviruses': 0,\n",
       " 'simulation': 0,\n",
       " '1.2': 0,\n",
       " 'part': 0,\n",
       " 'closeness': 1,\n",
       " 'transmission': 0,\n",
       " 'tasks': 0,\n",
       " 'make': 0,\n",
       " 'majority': 0,\n",
       " 'cooperating': 0,\n",
       " '500': 1,\n",
       " 'found': 1,\n",
       " 'convolution': 0,\n",
       " 'considerably': 0,\n",
       " 'imagenet': 0,\n",
       " 'connectivity': 0,\n",
       " 'words,': 1,\n",
       " 'detection': 0,\n",
       " 'demonstrate': 0,\n",
       " 'network,': 0,\n",
       " 'textual': 2,\n",
       " 'single-photon': 0,\n",
       " 'could': 0,\n",
       " 'redoing': 0,\n",
       " 'cpu': 0,\n",
       " '100-mode': 0,\n",
       " 'single-mode': 0,\n",
       " 'test': 0,\n",
       " 'would': 0,\n",
       " 'factor': 0,\n",
       " 'neurons': 0,\n",
       " 'structure.': 0,\n",
       " 'aerosols,': 0,\n",
       " 'network': 0,\n",
       " 'states': 0,\n",
       " 'entry.': 0,\n",
       " 'coronaviruses,': 0,\n",
       " 'power': 0,\n",
       " 'bag': 2,\n",
       " 'toward': 0,\n",
       " 'coronavirus': 0,\n",
       " 'samples': 0,\n",
       " 'indistinguishable': 0,\n",
       " 'released.': 1,\n",
       " 'requires': 0,\n",
       " 'method': 0,\n",
       " 'face': 0,\n",
       " 'facto': 1,\n",
       " 'distribution.': 0,\n",
       " '37.5%': 0,\n",
       " 'actual': 1,\n",
       " 'digital': 0,\n",
       " 'analysis': 2,\n",
       " 'performs': 1,\n",
       " 'prevent': 0,\n",
       " 'engine': 1,\n",
       " 's&p': 1,\n",
       " 'final': 0,\n",
       " 'validated': 0,\n",
       " 'clicks,': 0,\n",
       " 'plausible': 0,\n",
       " 'rate': 0,\n",
       " 'article': 3,\n",
       " 'covering': 1,\n",
       " 'full': 0,\n",
       " 'perform': 0,\n",
       " 'third': 0,\n",
       " 'phase-locked—and': 0,\n",
       " 'directly': 0,\n",
       " 'controlled': 0,\n",
       " 'variables,': 1,\n",
       " 'deep': 0,\n",
       " 'random': 0,\n",
       " 'rhinoviruses': 0,\n",
       " 'promise': 0,\n",
       " 'show': 1,\n",
       " 'applied': 1,\n",
       " 'ilsvrc-2012': 0,\n",
       " '17.0%': 0,\n",
       " 'price': 5,\n",
       " 'second-best': 0,\n",
       " 'predictive': 1,\n",
       " 'broadcast': 0,\n",
       " 'changed': 0,\n",
       " 'interferometer': 0,\n",
       " 'approach,': 1,\n",
       " 'error': 0,\n",
       " 'pool': 0,\n",
       " 'gaussian': 0,\n",
       " 'top-1': 0,\n",
       " '9,211': 1,\n",
       " 'vector': 1,\n",
       " 'nodes': 0,\n",
       " 'trusted': 0,\n",
       " 'hashing': 0,\n",
       " 'state-of-the-art.': 0,\n",
       " 'state-space': 0,\n",
       " 'exploiting': 0,\n",
       " 'large,': 0,\n",
       " 'chain': 0,\n",
       " 'allow': 0,\n",
       " 'proof': 0,\n",
       " '50': 0,\n",
       " 'effort': 0,\n",
       " 'classes.': 0,\n",
       " '(2.06%': 1,\n",
       " 'viruses': 0,\n",
       " 'faster,': 0,\n",
       " 'photons,': 0,\n",
       " 'indicate': 0,\n",
       " 'human': 0,\n",
       " 'entered': 0,\n",
       " 'compared': 0,\n",
       " 'uniform': 0,\n",
       " 'cash': 0,\n",
       " 'double-spending.': 0,\n",
       " 'minutes': 1,\n",
       " 'time': 1,\n",
       " 'distinguishable': 0,\n",
       " 'rna': 0,\n",
       " 'without': 0,\n",
       " 'faster': 0,\n",
       " 'droplets.': 0,\n",
       " 'approach': 1,\n",
       " 'competition': 0,\n",
       " 'consists': 0,\n",
       " 'also': 0,\n",
       " 'standard': 1,\n",
       " 'articles': 2,\n",
       " 'solution,': 0,\n",
       " 'quotes': 1,\n",
       " 'forming': 0,\n",
       " 'simulated': 1,\n",
       " '(svm)': 1,\n",
       " 'implementation': 0,\n",
       " 'noun': 2,\n",
       " 'operation.': 0,\n",
       " 'variant': 0,\n",
       " 'trained': 0,\n",
       " 'softmax': 0,\n",
       " 'release': 1,\n",
       " 'problem': 0,\n",
       " 'transactions': 0,\n",
       " 'symptomatic': 0,\n",
       " 'strong': 0,\n",
       " 'jiuzhang,': 0,\n",
       " 'illness.': 0,\n",
       " 'direction': 1,\n",
       " 'metrics.': 1,\n",
       " 'high-resolution': 0,\n",
       " 'solution': 0,\n",
       " 'supercomputers': 0,\n",
       " 'proper': 1,\n",
       " 'task': 0,\n",
       " 'hypotheses': 0,\n",
       " 'lsvrc-2010': 0,\n",
       " 'support': 1,\n",
       " 'classify': 0,\n",
       " 'softmax.': 0,\n",
       " 'advantage.': 0,\n",
       " 'seasonal': 0,\n",
       " 'million': 0,\n",
       " 'masks': 0,\n",
       " 'gone.': 0,\n",
       " '1030': 0,\n",
       " 'minimal': 0,\n",
       " 'gpu': 0,\n",
       " 'rates': 0,\n",
       " 'generates': 0,\n",
       " 'performance': 1,\n",
       " 'attackers.': 0,\n",
       " 'trading': 1,\n",
       " 'largest': 0,\n",
       " 'five': 1,\n",
       " 'payments': 0,\n",
       " '26.2%': 0,\n",
       " 'sent': 0,\n",
       " 'adults': 0,\n",
       " 'still': 0,\n",
       " 'matrix—the': 0,\n",
       " 'longest': 0,\n",
       " 'machine': 2,\n",
       " 'examines': 1,\n",
       " 'estimate': 1,\n",
       " 'individuals.': 0,\n",
       " '15.3%,': 0,\n",
       " 'best': 1,\n",
       " 'party': 0,\n",
       " 'proved': 0,\n",
       " 'quantum': 0,\n",
       " 'squeezed': 0,\n",
       " 'influenza': 0,\n",
       " 'stocks': 1,\n",
       " 'power.': 0,\n",
       " 'yields': 0,\n",
       " 'followed': 0,\n",
       " 'intractable': 0,\n",
       " 'main': 0,\n",
       " 'required': 0,\n",
       " 'proof-of-work.': 0,\n",
       " 'employed': 0,\n",
       " 'believed': 0,\n",
       " 'dimension': 0,\n",
       " '60': 0,\n",
       " 'three': 1,\n",
       " 'double-spending': 0,\n",
       " 'computer,': 0,\n",
       " 'propose': 0,\n",
       " 'setup': 0,\n",
       " 'came': 0,\n",
       " 'another': 0,\n",
       " 'convolutional': 0,\n",
       " 'de': 1,\n",
       " 'using': 3,\n",
       " 'institution.': 0,\n",
       " 'ongoing': 0,\n",
       " 'accepting': 0,\n",
       " '1000': 0,\n",
       " 'specially': 1,\n",
       " 'top-5': 0,\n",
       " 'representations:': 1,\n",
       " 'acute': 0,\n",
       " 'happened': 0,\n",
       " 'non-saturating': 0,\n",
       " 'recently-developed': 0,\n",
       " 'high-efficiency': 0,\n",
       " 'research': 1,\n",
       " 'investigated': 2,\n",
       " 'classical': 0,\n",
       " 'obtained': 0,\n",
       " 'witnessed,': 0,\n",
       " 'derivative': 1,\n",
       " 'max-pooling': 0,\n",
       " '0.04261),': 1,\n",
       " '~1014.': 0,\n",
       " 'network.': 0,\n",
       " '100': 0,\n",
       " 'representations': 1,\n",
       " 'stock-specific': 1,\n",
       " 'boson': 0,\n",
       " 'signatures': 0,\n",
       " 'ultralow-loss': 0,\n",
       " 'optical': 0,\n",
       " 'highest': 1,\n",
       " 'numeric': 1,\n",
       " 'better': 1,\n",
       " 'going': 0,\n",
       " 'peer-to-peer': 0,\n",
       " 'thermal': 0,\n",
       " 'benefits': 0,\n",
       " 'droplets': 0,\n",
       " 'sending': 0,\n",
       " 'winning': 0,\n",
       " 'neurons,': 0,\n",
       " 'efficient': 0,\n",
       " 'messages': 0,\n",
       " 'electronic': 0,\n",
       " 'several': 1,\n",
       " 'layers,': 0,\n",
       " 'terms': 1,\n",
       " 'timestamps': 0,\n",
       " 'entities.': 1,\n",
       " 'lost': 0,\n",
       " 'surgical': 0,\n",
       " 'version': 0,\n",
       " 'considered': 0,\n",
       " 'stock': 4,\n",
       " 'period.': 1,\n",
       " '(57.1%': 1,\n",
       " 'containing': 2,\n",
       " 'regularization': 0,\n",
       " 'tailored': 1,\n",
       " 'cannot': 0,\n",
       " 'overfitting': 0,\n",
       " '1000-way': 0,\n",
       " 'attack': 0,\n",
       " 'achieved': 0,\n",
       " 'data,': 0,\n",
       " 'online': 0,\n",
       " 'proof-of-work': 0,\n",
       " 'words': 1,\n",
       " 'training': 0,\n",
       " 'one': 0,\n",
       " 'children': 0,\n",
       " 'events': 0,\n",
       " 'leave': 0,\n",
       " 'computers.': 0,\n",
       " 'financial': 2,\n",
       " 'fully-connected': 0,\n",
       " 'whole': 0,\n",
       " 'states,': 0,\n",
       " '76': 0,\n",
       " 'exhaled': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1_wordDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba4f8098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>reduced</th>\n",
       "      <th>reduce</th>\n",
       "      <th>models</th>\n",
       "      <th>week</th>\n",
       "      <th>return).</th>\n",
       "      <th>effective.</th>\n",
       "      <th>(mse</th>\n",
       "      <th>learning</th>\n",
       "      <th>images</th>\n",
       "      <th>...</th>\n",
       "      <th>children</th>\n",
       "      <th>events</th>\n",
       "      <th>leave</th>\n",
       "      <th>computers.</th>\n",
       "      <th>financial</th>\n",
       "      <th>fully-connected</th>\n",
       "      <th>whole</th>\n",
       "      <th>states,</th>\n",
       "      <th>76</th>\n",
       "      <th>exhaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  reduced  reduce  models  week  return).  effective.  (mse  \\\n",
       "0           1        0       0       1     1         1           0     1   \n",
       "1           0        0       1       0     0         0           1     0   \n",
       "2           0        0       0       0     0         0           0     0   \n",
       "3           0        2       0       0     0         0           0     0   \n",
       "4           0        0       0       0     0         0           0     0   \n",
       "5           0        0       0       0     0         0           0     0   \n",
       "\n",
       "   learning  images  ...  children  events  leave  computers.  financial  \\\n",
       "0         1       0  ...         0       0      0           0          2   \n",
       "1         0       1  ...         0       0      0           0          0   \n",
       "2         0       0  ...         0       1      1           0          1   \n",
       "3         0       0  ...         1       0      0           0          0   \n",
       "4         0       0  ...         0       0      0           1          0   \n",
       "5         0       1  ...         0       0      0           0          0   \n",
       "\n",
       "   fully-connected  whole  states,  76  exhaled  \n",
       "0                0      0        0   0        0  \n",
       "1                2      0        0   0        0  \n",
       "2                0      0        0   0        0  \n",
       "3                0      0        0   0        1  \n",
       "4                0      1        1   1        0  \n",
       "5                1      0        0   0        0  \n",
       "\n",
       "[6 rows x 360 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using pandas library create a dataframe(table) using the dictionaries created above to visualise the data with the frequency of each word appear in each sentences\n",
    "pd.DataFrame([doc1_wordDict, doc2_wordDict, doc3_wordDict,doc4_wordDict, doc5_wordDict, query_wordDict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1959b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d359c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copute the TF values for each sentence\n",
    "tfDoc1 = computeTF(doc1_wordDict, doc1_filtered_sentence)\n",
    "tfDoc2 = computeTF(doc2_wordDict, doc2_filtered_sentence)\n",
    "tfDoc3 = computeTF(doc3_wordDict, doc3_filtered_sentence)\n",
    "tfDoc4 = computeTF(doc4_wordDict, doc4_filtered_sentence)\n",
    "tfDoc5 = computeTF(doc5_wordDict, doc5_filtered_sentence)\n",
    "tfQuery = computeTF(query_wordDict, query_filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d576998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 0.008620689655172414,\n",
       " 'reduced': 0.0,\n",
       " 'reduce': 0.0,\n",
       " 'models': 0.008620689655172414,\n",
       " 'week': 0.008620689655172414,\n",
       " 'return).': 0.008620689655172414,\n",
       " 'effective.': 0.0,\n",
       " '(mse': 0.008620689655172414,\n",
       " 'learning': 0.008620689655172414,\n",
       " 'images': 0.0,\n",
       " 'return': 0.008620689655172414,\n",
       " 'computers': 0.0,\n",
       " 'output': 0.0,\n",
       " 'detectors.': 0.0,\n",
       " 'sequence': 0.0,\n",
       " '10,259,042': 0.008620689655172414,\n",
       " 'photon': 0.0,\n",
       " 'scheme': 0.008620689655172414,\n",
       " 'basis,': 0.0,\n",
       " 'performed': 0.0,\n",
       " 'photonic': 0.0,\n",
       " 'parameters': 0.0,\n",
       " 'contest': 0.0,\n",
       " 'they’ll': 0.0,\n",
       " 'identified': 0.0,\n",
       " 'news': 0.02586206896551724,\n",
       " 'phrases,': 0.008620689655172414,\n",
       " '“dropout”': 0.0,\n",
       " 'respiratory': 0.0,\n",
       " 'future': 0.017241379310344827,\n",
       " 'certain': 0.0,\n",
       " 'record': 0.0,\n",
       " 'purely': 0.0,\n",
       " 'layers': 0.0,\n",
       " 'different': 0.02586206896551724,\n",
       " 'computational': 0.0,\n",
       " 'movement': 0.008620689655172414,\n",
       " 'neural': 0.0,\n",
       " 'previous': 0.0,\n",
       " 'hash-based': 0.0,\n",
       " 'significantly': 0.0,\n",
       " 'candidate': 0.0,\n",
       " '650,000': 0.0,\n",
       " 'named': 0.008620689655172414,\n",
       " 'called': 0.0,\n",
       " 'generate': 0.0,\n",
       " 'coughs': 0.0,\n",
       " 'virus': 0.0,\n",
       " 'used': 0.0,\n",
       " 'strategy': 0.0,\n",
       " 'accuracy)': 0.008620689655172414,\n",
       " 'state-of-the-art': 0.0,\n",
       " 'trend': 0.0,\n",
       " 'serves': 0.0,\n",
       " 'model': 0.008620689655172414,\n",
       " 'proof-of-work,': 0.0,\n",
       " 'results': 0.0,\n",
       " 'outpace': 0.0,\n",
       " 'sampling': 0.0,\n",
       " 'directional': 0.008620689655172414,\n",
       " 'discrete': 0.017241379310344827,\n",
       " 'breath': 0.0,\n",
       " 'twenty': 0.008620689655172414,\n",
       " 'will,': 0.0,\n",
       " 'provide': 0.0,\n",
       " 'rejoin': 0.0,\n",
       " 'long': 0.0,\n",
       " 'coronaviruses': 0.0,\n",
       " 'simulation': 0.0,\n",
       " '1.2': 0.0,\n",
       " 'part': 0.0,\n",
       " 'closeness': 0.008620689655172414,\n",
       " 'transmission': 0.0,\n",
       " 'tasks': 0.0,\n",
       " 'make': 0.0,\n",
       " 'majority': 0.0,\n",
       " 'cooperating': 0.0,\n",
       " '500': 0.008620689655172414,\n",
       " 'found': 0.008620689655172414,\n",
       " 'convolution': 0.0,\n",
       " 'considerably': 0.0,\n",
       " 'imagenet': 0.0,\n",
       " 'connectivity': 0.0,\n",
       " 'words,': 0.008620689655172414,\n",
       " 'detection': 0.0,\n",
       " 'demonstrate': 0.0,\n",
       " 'network,': 0.0,\n",
       " 'textual': 0.017241379310344827,\n",
       " 'single-photon': 0.0,\n",
       " 'could': 0.0,\n",
       " 'redoing': 0.0,\n",
       " 'cpu': 0.0,\n",
       " '100-mode': 0.0,\n",
       " 'single-mode': 0.0,\n",
       " 'test': 0.0,\n",
       " 'would': 0.0,\n",
       " 'factor': 0.0,\n",
       " 'neurons': 0.0,\n",
       " 'structure.': 0.0,\n",
       " 'aerosols,': 0.0,\n",
       " 'network': 0.0,\n",
       " 'states': 0.0,\n",
       " 'entry.': 0.0,\n",
       " 'coronaviruses,': 0.0,\n",
       " 'power': 0.0,\n",
       " 'bag': 0.017241379310344827,\n",
       " 'toward': 0.0,\n",
       " 'coronavirus': 0.0,\n",
       " 'samples': 0.0,\n",
       " 'indistinguishable': 0.0,\n",
       " 'released.': 0.008620689655172414,\n",
       " 'requires': 0.0,\n",
       " 'method': 0.0,\n",
       " 'face': 0.0,\n",
       " 'facto': 0.008620689655172414,\n",
       " 'distribution.': 0.0,\n",
       " '37.5%': 0.0,\n",
       " 'actual': 0.008620689655172414,\n",
       " 'digital': 0.0,\n",
       " 'analysis': 0.017241379310344827,\n",
       " 'performs': 0.008620689655172414,\n",
       " 'prevent': 0.0,\n",
       " 'engine': 0.008620689655172414,\n",
       " 's&p': 0.008620689655172414,\n",
       " 'final': 0.0,\n",
       " 'validated': 0.0,\n",
       " 'clicks,': 0.0,\n",
       " 'plausible': 0.0,\n",
       " 'rate': 0.0,\n",
       " 'article': 0.02586206896551724,\n",
       " 'covering': 0.008620689655172414,\n",
       " 'full': 0.0,\n",
       " 'perform': 0.0,\n",
       " 'third': 0.0,\n",
       " 'phase-locked—and': 0.0,\n",
       " 'directly': 0.0,\n",
       " 'controlled': 0.0,\n",
       " 'variables,': 0.008620689655172414,\n",
       " 'deep': 0.0,\n",
       " 'random': 0.0,\n",
       " 'rhinoviruses': 0.0,\n",
       " 'promise': 0.0,\n",
       " 'show': 0.008620689655172414,\n",
       " 'applied': 0.008620689655172414,\n",
       " 'ilsvrc-2012': 0.0,\n",
       " '17.0%': 0.0,\n",
       " 'price': 0.04310344827586207,\n",
       " 'second-best': 0.0,\n",
       " 'predictive': 0.008620689655172414,\n",
       " 'broadcast': 0.0,\n",
       " 'changed': 0.0,\n",
       " 'interferometer': 0.0,\n",
       " 'approach,': 0.008620689655172414,\n",
       " 'error': 0.0,\n",
       " 'pool': 0.0,\n",
       " 'gaussian': 0.0,\n",
       " 'top-1': 0.0,\n",
       " '9,211': 0.008620689655172414,\n",
       " 'vector': 0.008620689655172414,\n",
       " 'nodes': 0.0,\n",
       " 'trusted': 0.0,\n",
       " 'hashing': 0.0,\n",
       " 'state-of-the-art.': 0.0,\n",
       " 'state-space': 0.0,\n",
       " 'exploiting': 0.0,\n",
       " 'large,': 0.0,\n",
       " 'chain': 0.0,\n",
       " 'allow': 0.0,\n",
       " 'proof': 0.0,\n",
       " '50': 0.0,\n",
       " 'effort': 0.0,\n",
       " 'classes.': 0.0,\n",
       " '(2.06%': 0.008620689655172414,\n",
       " 'viruses': 0.0,\n",
       " 'faster,': 0.0,\n",
       " 'photons,': 0.0,\n",
       " 'indicate': 0.0,\n",
       " 'human': 0.0,\n",
       " 'entered': 0.0,\n",
       " 'compared': 0.0,\n",
       " 'uniform': 0.0,\n",
       " 'cash': 0.0,\n",
       " 'double-spending.': 0.0,\n",
       " 'minutes': 0.008620689655172414,\n",
       " 'time': 0.008620689655172414,\n",
       " 'distinguishable': 0.0,\n",
       " 'rna': 0.0,\n",
       " 'without': 0.0,\n",
       " 'faster': 0.0,\n",
       " 'droplets.': 0.0,\n",
       " 'approach': 0.008620689655172414,\n",
       " 'competition': 0.0,\n",
       " 'consists': 0.0,\n",
       " 'also': 0.0,\n",
       " 'standard': 0.008620689655172414,\n",
       " 'articles': 0.017241379310344827,\n",
       " 'solution,': 0.0,\n",
       " 'quotes': 0.008620689655172414,\n",
       " 'forming': 0.0,\n",
       " 'simulated': 0.008620689655172414,\n",
       " '(svm)': 0.008620689655172414,\n",
       " 'implementation': 0.0,\n",
       " 'noun': 0.017241379310344827,\n",
       " 'operation.': 0.0,\n",
       " 'variant': 0.0,\n",
       " 'trained': 0.0,\n",
       " 'softmax': 0.0,\n",
       " 'release': 0.008620689655172414,\n",
       " 'problem': 0.0,\n",
       " 'transactions': 0.0,\n",
       " 'symptomatic': 0.0,\n",
       " 'strong': 0.0,\n",
       " 'jiuzhang,': 0.0,\n",
       " 'illness.': 0.0,\n",
       " 'direction': 0.008620689655172414,\n",
       " 'metrics.': 0.008620689655172414,\n",
       " 'high-resolution': 0.0,\n",
       " 'solution': 0.0,\n",
       " 'supercomputers': 0.0,\n",
       " 'proper': 0.008620689655172414,\n",
       " 'task': 0.0,\n",
       " 'hypotheses': 0.0,\n",
       " 'lsvrc-2010': 0.0,\n",
       " 'support': 0.008620689655172414,\n",
       " 'classify': 0.0,\n",
       " 'softmax.': 0.0,\n",
       " 'advantage.': 0.0,\n",
       " 'seasonal': 0.0,\n",
       " 'million': 0.0,\n",
       " 'masks': 0.0,\n",
       " 'gone.': 0.0,\n",
       " '1030': 0.0,\n",
       " 'minimal': 0.0,\n",
       " 'gpu': 0.0,\n",
       " 'rates': 0.0,\n",
       " 'generates': 0.0,\n",
       " 'performance': 0.008620689655172414,\n",
       " 'attackers.': 0.0,\n",
       " 'trading': 0.008620689655172414,\n",
       " 'largest': 0.0,\n",
       " 'five': 0.008620689655172414,\n",
       " 'payments': 0.0,\n",
       " '26.2%': 0.0,\n",
       " 'sent': 0.0,\n",
       " 'adults': 0.0,\n",
       " 'still': 0.0,\n",
       " 'matrix—the': 0.0,\n",
       " 'longest': 0.0,\n",
       " 'machine': 0.017241379310344827,\n",
       " 'examines': 0.008620689655172414,\n",
       " 'estimate': 0.008620689655172414,\n",
       " 'individuals.': 0.0,\n",
       " '15.3%,': 0.0,\n",
       " 'best': 0.008620689655172414,\n",
       " 'party': 0.0,\n",
       " 'proved': 0.0,\n",
       " 'quantum': 0.0,\n",
       " 'squeezed': 0.0,\n",
       " 'influenza': 0.0,\n",
       " 'stocks': 0.008620689655172414,\n",
       " 'power.': 0.0,\n",
       " 'yields': 0.0,\n",
       " 'followed': 0.0,\n",
       " 'intractable': 0.0,\n",
       " 'main': 0.0,\n",
       " 'required': 0.0,\n",
       " 'proof-of-work.': 0.0,\n",
       " 'employed': 0.0,\n",
       " 'believed': 0.0,\n",
       " 'dimension': 0.0,\n",
       " '60': 0.0,\n",
       " 'three': 0.008620689655172414,\n",
       " 'double-spending': 0.0,\n",
       " 'computer,': 0.0,\n",
       " 'propose': 0.0,\n",
       " 'setup': 0.0,\n",
       " 'came': 0.0,\n",
       " 'another': 0.0,\n",
       " 'convolutional': 0.0,\n",
       " 'de': 0.008620689655172414,\n",
       " 'using': 0.02586206896551724,\n",
       " 'institution.': 0.0,\n",
       " 'ongoing': 0.0,\n",
       " 'accepting': 0.0,\n",
       " '1000': 0.0,\n",
       " 'specially': 0.008620689655172414,\n",
       " 'top-5': 0.0,\n",
       " 'representations:': 0.008620689655172414,\n",
       " 'acute': 0.0,\n",
       " 'happened': 0.0,\n",
       " 'non-saturating': 0.0,\n",
       " 'recently-developed': 0.0,\n",
       " 'high-efficiency': 0.0,\n",
       " 'research': 0.008620689655172414,\n",
       " 'investigated': 0.017241379310344827,\n",
       " 'classical': 0.0,\n",
       " 'obtained': 0.0,\n",
       " 'witnessed,': 0.0,\n",
       " 'derivative': 0.008620689655172414,\n",
       " 'max-pooling': 0.0,\n",
       " '0.04261),': 0.008620689655172414,\n",
       " '~1014.': 0.0,\n",
       " 'network.': 0.0,\n",
       " '100': 0.0,\n",
       " 'representations': 0.008620689655172414,\n",
       " 'stock-specific': 0.008620689655172414,\n",
       " 'boson': 0.0,\n",
       " 'signatures': 0.0,\n",
       " 'ultralow-loss': 0.0,\n",
       " 'optical': 0.0,\n",
       " 'highest': 0.008620689655172414,\n",
       " 'numeric': 0.008620689655172414,\n",
       " 'better': 0.008620689655172414,\n",
       " 'going': 0.0,\n",
       " 'peer-to-peer': 0.0,\n",
       " 'thermal': 0.0,\n",
       " 'benefits': 0.0,\n",
       " 'droplets': 0.0,\n",
       " 'sending': 0.0,\n",
       " 'winning': 0.0,\n",
       " 'neurons,': 0.0,\n",
       " 'efficient': 0.0,\n",
       " 'messages': 0.0,\n",
       " 'electronic': 0.0,\n",
       " 'several': 0.008620689655172414,\n",
       " 'layers,': 0.0,\n",
       " 'terms': 0.008620689655172414,\n",
       " 'timestamps': 0.0,\n",
       " 'entities.': 0.008620689655172414,\n",
       " 'lost': 0.0,\n",
       " 'surgical': 0.0,\n",
       " 'version': 0.0,\n",
       " 'considered': 0.0,\n",
       " 'stock': 0.034482758620689655,\n",
       " 'period.': 0.008620689655172414,\n",
       " '(57.1%': 0.008620689655172414,\n",
       " 'containing': 0.017241379310344827,\n",
       " 'regularization': 0.0,\n",
       " 'tailored': 0.008620689655172414,\n",
       " 'cannot': 0.0,\n",
       " 'overfitting': 0.0,\n",
       " '1000-way': 0.0,\n",
       " 'attack': 0.0,\n",
       " 'achieved': 0.0,\n",
       " 'data,': 0.0,\n",
       " 'online': 0.0,\n",
       " 'proof-of-work': 0.0,\n",
       " 'words': 0.008620689655172414,\n",
       " 'training': 0.0,\n",
       " 'one': 0.0,\n",
       " 'children': 0.0,\n",
       " 'events': 0.0,\n",
       " 'leave': 0.0,\n",
       " 'computers.': 0.0,\n",
       " 'financial': 0.017241379310344827,\n",
       " 'fully-connected': 0.0,\n",
       " 'whole': 0.0,\n",
       " 'states,': 0.0,\n",
       " '76': 0.0,\n",
       " 'exhaled': 0.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfDoc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acea93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to calculate the Inverse Document Frequency\n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e42fa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use the computeIDF function to compute IDF\n",
    "idfs = computeIDF([doc1_wordDict, doc2_wordDict, doc3_wordDict, doc4_wordDict, doc5_wordDict, query_wordDict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "649c78e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 0.7781512503836436,\n",
       " 'reduced': 0.7781512503836436,\n",
       " 'reduce': 0.7781512503836436,\n",
       " 'models': 0.7781512503836436,\n",
       " 'week': 0.7781512503836436,\n",
       " 'return).': 0.7781512503836436,\n",
       " 'effective.': 0.7781512503836436,\n",
       " '(mse': 0.7781512503836436,\n",
       " 'learning': 0.7781512503836436,\n",
       " 'images': 0.47712125471966244,\n",
       " 'return': 0.7781512503836436,\n",
       " 'computers': 0.7781512503836436,\n",
       " 'output': 0.7781512503836436,\n",
       " 'detectors.': 0.7781512503836436,\n",
       " 'sequence': 0.7781512503836436,\n",
       " '10,259,042': 0.7781512503836436,\n",
       " 'photon': 0.7781512503836436,\n",
       " 'scheme': 0.7781512503836436,\n",
       " 'basis,': 0.7781512503836436,\n",
       " 'performed': 0.7781512503836436,\n",
       " 'photonic': 0.7781512503836436,\n",
       " 'parameters': 0.47712125471966244,\n",
       " 'contest': 0.47712125471966244,\n",
       " 'they’ll': 0.7781512503836436,\n",
       " 'identified': 0.7781512503836436,\n",
       " 'news': 0.7781512503836436,\n",
       " 'phrases,': 0.7781512503836436,\n",
       " '“dropout”': 0.7781512503836436,\n",
       " 'respiratory': 0.7781512503836436,\n",
       " 'future': 0.7781512503836436,\n",
       " 'certain': 0.7781512503836436,\n",
       " 'record': 0.7781512503836436,\n",
       " 'purely': 0.7781512503836436,\n",
       " 'layers': 0.47712125471966244,\n",
       " 'different': 0.3010299956639812,\n",
       " 'computational': 0.7781512503836436,\n",
       " 'movement': 0.7781512503836436,\n",
       " 'neural': 0.47712125471966244,\n",
       " 'previous': 0.7781512503836436,\n",
       " 'hash-based': 0.7781512503836436,\n",
       " 'significantly': 0.7781512503836436,\n",
       " 'candidate': 0.7781512503836436,\n",
       " '650,000': 0.47712125471966244,\n",
       " 'named': 0.7781512503836436,\n",
       " 'called': 0.7781512503836436,\n",
       " 'generate': 0.7781512503836436,\n",
       " 'coughs': 0.7781512503836436,\n",
       " 'virus': 0.7781512503836436,\n",
       " 'used': 0.7781512503836436,\n",
       " 'strategy': 0.7781512503836436,\n",
       " 'accuracy)': 0.7781512503836436,\n",
       " 'state-of-the-art': 0.7781512503836436,\n",
       " 'trend': 0.7781512503836436,\n",
       " 'serves': 0.7781512503836436,\n",
       " 'model': 0.47712125471966244,\n",
       " 'proof-of-work,': 0.7781512503836436,\n",
       " 'results': 0.7781512503836436,\n",
       " 'outpace': 0.7781512503836436,\n",
       " 'sampling': 0.7781512503836436,\n",
       " 'directional': 0.7781512503836436,\n",
       " 'discrete': 0.7781512503836436,\n",
       " 'breath': 0.7781512503836436,\n",
       " 'twenty': 0.7781512503836436,\n",
       " 'will,': 0.7781512503836436,\n",
       " 'provide': 0.7781512503836436,\n",
       " 'rejoin': 0.7781512503836436,\n",
       " 'long': 0.7781512503836436,\n",
       " 'coronaviruses': 0.7781512503836436,\n",
       " 'simulation': 0.7781512503836436,\n",
       " '1.2': 0.47712125471966244,\n",
       " 'part': 0.7781512503836436,\n",
       " 'closeness': 0.7781512503836436,\n",
       " 'transmission': 0.7781512503836436,\n",
       " 'tasks': 0.7781512503836436,\n",
       " 'make': 0.7781512503836436,\n",
       " 'majority': 0.7781512503836436,\n",
       " 'cooperating': 0.7781512503836436,\n",
       " '500': 0.7781512503836436,\n",
       " 'found': 0.7781512503836436,\n",
       " 'convolution': 0.7781512503836436,\n",
       " 'considerably': 0.7781512503836436,\n",
       " 'imagenet': 0.47712125471966244,\n",
       " 'connectivity': 0.7781512503836436,\n",
       " 'words,': 0.7781512503836436,\n",
       " 'detection': 0.7781512503836436,\n",
       " 'demonstrate': 0.7781512503836436,\n",
       " 'network,': 0.3010299956639812,\n",
       " 'textual': 0.7781512503836436,\n",
       " 'single-photon': 0.7781512503836436,\n",
       " 'could': 0.7781512503836436,\n",
       " 'redoing': 0.7781512503836436,\n",
       " 'cpu': 0.7781512503836436,\n",
       " '100-mode': 0.7781512503836436,\n",
       " 'single-mode': 0.7781512503836436,\n",
       " 'test': 0.7781512503836436,\n",
       " 'would': 0.7781512503836436,\n",
       " 'factor': 0.7781512503836436,\n",
       " 'neurons': 0.7781512503836436,\n",
       " 'structure.': 0.7781512503836436,\n",
       " 'aerosols,': 0.7781512503836436,\n",
       " 'network': 0.47712125471966244,\n",
       " 'states': 0.7781512503836436,\n",
       " 'entry.': 0.7781512503836436,\n",
       " 'coronaviruses,': 0.7781512503836436,\n",
       " 'power': 0.7781512503836436,\n",
       " 'bag': 0.7781512503836436,\n",
       " 'toward': 0.7781512503836436,\n",
       " 'coronavirus': 0.7781512503836436,\n",
       " 'samples': 0.7781512503836436,\n",
       " 'indistinguishable': 0.7781512503836436,\n",
       " 'released.': 0.7781512503836436,\n",
       " 'requires': 0.7781512503836436,\n",
       " 'method': 0.7781512503836436,\n",
       " 'face': 0.7781512503836436,\n",
       " 'facto': 0.7781512503836436,\n",
       " 'distribution.': 0.7781512503836436,\n",
       " '37.5%': 0.7781512503836436,\n",
       " 'actual': 0.7781512503836436,\n",
       " 'digital': 0.7781512503836436,\n",
       " 'analysis': 0.7781512503836436,\n",
       " 'performs': 0.7781512503836436,\n",
       " 'prevent': 0.47712125471966244,\n",
       " 'engine': 0.7781512503836436,\n",
       " 's&p': 0.7781512503836436,\n",
       " 'final': 0.47712125471966244,\n",
       " 'validated': 0.7781512503836436,\n",
       " 'clicks,': 0.7781512503836436,\n",
       " 'plausible': 0.7781512503836436,\n",
       " 'rate': 0.47712125471966244,\n",
       " 'article': 0.7781512503836436,\n",
       " 'covering': 0.7781512503836436,\n",
       " 'full': 0.7781512503836436,\n",
       " 'perform': 0.7781512503836436,\n",
       " 'third': 0.7781512503836436,\n",
       " 'phase-locked—and': 0.7781512503836436,\n",
       " 'directly': 0.7781512503836436,\n",
       " 'controlled': 0.7781512503836436,\n",
       " 'variables,': 0.7781512503836436,\n",
       " 'deep': 0.47712125471966244,\n",
       " 'random': 0.7781512503836436,\n",
       " 'rhinoviruses': 0.7781512503836436,\n",
       " 'promise': 0.7781512503836436,\n",
       " 'show': 0.7781512503836436,\n",
       " 'applied': 0.7781512503836436,\n",
       " 'ilsvrc-2012': 0.7781512503836436,\n",
       " '17.0%': 0.7781512503836436,\n",
       " 'price': 0.7781512503836436,\n",
       " 'second-best': 0.7781512503836436,\n",
       " 'predictive': 0.7781512503836436,\n",
       " 'broadcast': 0.7781512503836436,\n",
       " 'changed': 0.7781512503836436,\n",
       " 'interferometer': 0.7781512503836436,\n",
       " 'approach,': 0.7781512503836436,\n",
       " 'error': 0.7781512503836436,\n",
       " 'pool': 0.7781512503836436,\n",
       " 'gaussian': 0.7781512503836436,\n",
       " 'top-1': 0.7781512503836436,\n",
       " '9,211': 0.7781512503836436,\n",
       " 'vector': 0.7781512503836436,\n",
       " 'nodes': 0.7781512503836436,\n",
       " 'trusted': 0.7781512503836436,\n",
       " 'hashing': 0.7781512503836436,\n",
       " 'state-of-the-art.': 0.7781512503836436,\n",
       " 'state-space': 0.7781512503836436,\n",
       " 'exploiting': 0.7781512503836436,\n",
       " 'large,': 0.7781512503836436,\n",
       " 'chain': 0.7781512503836436,\n",
       " 'allow': 0.7781512503836436,\n",
       " 'proof': 0.7781512503836436,\n",
       " '50': 0.7781512503836436,\n",
       " 'effort': 0.7781512503836436,\n",
       " 'classes.': 0.47712125471966244,\n",
       " '(2.06%': 0.7781512503836436,\n",
       " 'viruses': 0.7781512503836436,\n",
       " 'faster,': 0.7781512503836436,\n",
       " 'photons,': 0.7781512503836436,\n",
       " 'indicate': 0.7781512503836436,\n",
       " 'human': 0.7781512503836436,\n",
       " 'entered': 0.7781512503836436,\n",
       " 'compared': 0.7781512503836436,\n",
       " 'uniform': 0.7781512503836436,\n",
       " 'cash': 0.7781512503836436,\n",
       " 'double-spending.': 0.7781512503836436,\n",
       " 'minutes': 0.7781512503836436,\n",
       " 'time': 0.7781512503836436,\n",
       " 'distinguishable': 0.7781512503836436,\n",
       " 'rna': 0.7781512503836436,\n",
       " 'without': 0.7781512503836436,\n",
       " 'faster': 0.7781512503836436,\n",
       " 'droplets.': 0.7781512503836436,\n",
       " 'approach': 0.7781512503836436,\n",
       " 'competition': 0.7781512503836436,\n",
       " 'consists': 0.47712125471966244,\n",
       " 'also': 0.7781512503836436,\n",
       " 'standard': 0.7781512503836436,\n",
       " 'articles': 0.7781512503836436,\n",
       " 'solution,': 0.7781512503836436,\n",
       " 'quotes': 0.7781512503836436,\n",
       " 'forming': 0.7781512503836436,\n",
       " 'simulated': 0.7781512503836436,\n",
       " '(svm)': 0.7781512503836436,\n",
       " 'implementation': 0.7781512503836436,\n",
       " 'noun': 0.7781512503836436,\n",
       " 'operation.': 0.7781512503836436,\n",
       " 'variant': 0.7781512503836436,\n",
       " 'trained': 0.47712125471966244,\n",
       " 'softmax': 0.7781512503836436,\n",
       " 'release': 0.7781512503836436,\n",
       " 'problem': 0.7781512503836436,\n",
       " 'transactions': 0.7781512503836436,\n",
       " 'symptomatic': 0.7781512503836436,\n",
       " 'strong': 0.7781512503836436,\n",
       " 'jiuzhang,': 0.7781512503836436,\n",
       " 'illness.': 0.7781512503836436,\n",
       " 'direction': 0.7781512503836436,\n",
       " 'metrics.': 0.7781512503836436,\n",
       " 'high-resolution': 0.47712125471966244,\n",
       " 'solution': 0.7781512503836436,\n",
       " 'supercomputers': 0.7781512503836436,\n",
       " 'proper': 0.7781512503836436,\n",
       " 'task': 0.7781512503836436,\n",
       " 'hypotheses': 0.7781512503836436,\n",
       " 'lsvrc-2010': 0.47712125471966244,\n",
       " 'support': 0.7781512503836436,\n",
       " 'classify': 0.47712125471966244,\n",
       " 'softmax.': 0.7781512503836436,\n",
       " 'advantage.': 0.7781512503836436,\n",
       " 'seasonal': 0.7781512503836436,\n",
       " 'million': 0.47712125471966244,\n",
       " 'masks': 0.7781512503836436,\n",
       " 'gone.': 0.7781512503836436,\n",
       " '1030': 0.7781512503836436,\n",
       " 'minimal': 0.7781512503836436,\n",
       " 'gpu': 0.7781512503836436,\n",
       " 'rates': 0.7781512503836436,\n",
       " 'generates': 0.7781512503836436,\n",
       " 'performance': 0.7781512503836436,\n",
       " 'attackers.': 0.7781512503836436,\n",
       " 'trading': 0.7781512503836436,\n",
       " 'largest': 0.7781512503836436,\n",
       " 'five': 0.3010299956639812,\n",
       " 'payments': 0.7781512503836436,\n",
       " '26.2%': 0.7781512503836436,\n",
       " 'sent': 0.7781512503836436,\n",
       " 'adults': 0.7781512503836436,\n",
       " 'still': 0.7781512503836436,\n",
       " 'matrix—the': 0.7781512503836436,\n",
       " 'longest': 0.7781512503836436,\n",
       " 'machine': 0.7781512503836436,\n",
       " 'examines': 0.7781512503836436,\n",
       " 'estimate': 0.7781512503836436,\n",
       " 'individuals.': 0.7781512503836436,\n",
       " '15.3%,': 0.7781512503836436,\n",
       " 'best': 0.47712125471966244,\n",
       " 'party': 0.7781512503836436,\n",
       " 'proved': 0.7781512503836436,\n",
       " 'quantum': 0.7781512503836436,\n",
       " 'squeezed': 0.7781512503836436,\n",
       " 'influenza': 0.7781512503836436,\n",
       " 'stocks': 0.7781512503836436,\n",
       " 'power.': 0.7781512503836436,\n",
       " 'yields': 0.7781512503836436,\n",
       " 'followed': 0.47712125471966244,\n",
       " 'intractable': 0.7781512503836436,\n",
       " 'main': 0.7781512503836436,\n",
       " 'required': 0.7781512503836436,\n",
       " 'proof-of-work.': 0.7781512503836436,\n",
       " 'employed': 0.7781512503836436,\n",
       " 'believed': 0.7781512503836436,\n",
       " 'dimension': 0.7781512503836436,\n",
       " '60': 0.47712125471966244,\n",
       " 'three': 0.3010299956639812,\n",
       " 'double-spending': 0.7781512503836436,\n",
       " 'computer,': 0.7781512503836436,\n",
       " 'propose': 0.7781512503836436,\n",
       " 'setup': 0.7781512503836436,\n",
       " 'came': 0.7781512503836436,\n",
       " 'another': 0.7781512503836436,\n",
       " 'convolutional': 0.47712125471966244,\n",
       " 'de': 0.7781512503836436,\n",
       " 'using': 0.3010299956639812,\n",
       " 'institution.': 0.7781512503836436,\n",
       " 'ongoing': 0.7781512503836436,\n",
       " 'accepting': 0.7781512503836436,\n",
       " '1000': 0.47712125471966244,\n",
       " 'specially': 0.7781512503836436,\n",
       " 'top-5': 0.7781512503836436,\n",
       " 'representations:': 0.7781512503836436,\n",
       " 'acute': 0.7781512503836436,\n",
       " 'happened': 0.7781512503836436,\n",
       " 'non-saturating': 0.7781512503836436,\n",
       " 'recently-developed': 0.7781512503836436,\n",
       " 'high-efficiency': 0.7781512503836436,\n",
       " 'research': 0.7781512503836436,\n",
       " 'investigated': 0.7781512503836436,\n",
       " 'classical': 0.7781512503836436,\n",
       " 'obtained': 0.7781512503836436,\n",
       " 'witnessed,': 0.7781512503836436,\n",
       " 'derivative': 0.7781512503836436,\n",
       " 'max-pooling': 0.47712125471966244,\n",
       " '0.04261),': 0.7781512503836436,\n",
       " '~1014.': 0.7781512503836436,\n",
       " 'network.': 0.7781512503836436,\n",
       " '100': 0.7781512503836436,\n",
       " 'representations': 0.7781512503836436,\n",
       " 'stock-specific': 0.7781512503836436,\n",
       " 'boson': 0.7781512503836436,\n",
       " 'signatures': 0.7781512503836436,\n",
       " 'ultralow-loss': 0.7781512503836436,\n",
       " 'optical': 0.7781512503836436,\n",
       " 'highest': 0.7781512503836436,\n",
       " 'numeric': 0.7781512503836436,\n",
       " 'better': 0.47712125471966244,\n",
       " 'going': 0.7781512503836436,\n",
       " 'peer-to-peer': 0.7781512503836436,\n",
       " 'thermal': 0.7781512503836436,\n",
       " 'benefits': 0.7781512503836436,\n",
       " 'droplets': 0.7781512503836436,\n",
       " 'sending': 0.7781512503836436,\n",
       " 'winning': 0.7781512503836436,\n",
       " 'neurons,': 0.47712125471966244,\n",
       " 'efficient': 0.7781512503836436,\n",
       " 'messages': 0.7781512503836436,\n",
       " 'electronic': 0.7781512503836436,\n",
       " 'several': 0.7781512503836436,\n",
       " 'layers,': 0.47712125471966244,\n",
       " 'terms': 0.7781512503836436,\n",
       " 'timestamps': 0.7781512503836436,\n",
       " 'entities.': 0.7781512503836436,\n",
       " 'lost': 0.7781512503836436,\n",
       " 'surgical': 0.7781512503836436,\n",
       " 'version': 0.7781512503836436,\n",
       " 'considered': 0.7781512503836436,\n",
       " 'stock': 0.7781512503836436,\n",
       " 'period.': 0.7781512503836436,\n",
       " '(57.1%': 0.7781512503836436,\n",
       " 'containing': 0.7781512503836436,\n",
       " 'regularization': 0.7781512503836436,\n",
       " 'tailored': 0.7781512503836436,\n",
       " 'cannot': 0.7781512503836436,\n",
       " 'overfitting': 0.7781512503836436,\n",
       " '1000-way': 0.47712125471966244,\n",
       " 'attack': 0.7781512503836436,\n",
       " 'achieved': 0.7781512503836436,\n",
       " 'data,': 0.7781512503836436,\n",
       " 'online': 0.7781512503836436,\n",
       " 'proof-of-work': 0.7781512503836436,\n",
       " 'words': 0.7781512503836436,\n",
       " 'training': 0.7781512503836436,\n",
       " 'one': 0.7781512503836436,\n",
       " 'children': 0.7781512503836436,\n",
       " 'events': 0.7781512503836436,\n",
       " 'leave': 0.7781512503836436,\n",
       " 'computers.': 0.7781512503836436,\n",
       " 'financial': 0.47712125471966244,\n",
       " 'fully-connected': 0.47712125471966244,\n",
       " 'whole': 0.7781512503836436,\n",
       " 'states,': 0.7781512503836436,\n",
       " '76': 0.7781512503836436,\n",
       " 'exhaled': 0.7781512503836436}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96f5ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will calculate the TF*IDF value in a dictionary format\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3485bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDoc1 = computeTFIDF(tfDoc1, idfs)\n",
    "tfidfDoc2 = computeTFIDF(tfDoc2, idfs)\n",
    "tfidfDoc3 = computeTFIDF(tfDoc3, idfs)\n",
    "tfidfDoc4 = computeTFIDF(tfDoc4, idfs)\n",
    "tfidfDoc5 = computeTFIDF(tfDoc5, idfs)\n",
    "tfidfQuery = computeTFIDF(tfQuery, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26de1753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>reduced</th>\n",
       "      <th>reduce</th>\n",
       "      <th>models</th>\n",
       "      <th>week</th>\n",
       "      <th>return).</th>\n",
       "      <th>effective.</th>\n",
       "      <th>(mse</th>\n",
       "      <th>learning</th>\n",
       "      <th>images</th>\n",
       "      <th>...</th>\n",
       "      <th>children</th>\n",
       "      <th>events</th>\n",
       "      <th>leave</th>\n",
       "      <th>computers.</th>\n",
       "      <th>financial</th>\n",
       "      <th>fully-connected</th>\n",
       "      <th>whole</th>\n",
       "      <th>states,</th>\n",
       "      <th>76</th>\n",
       "      <th>exhaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction   reduced    reduce    models      week  return).  effective.  \\\n",
       "0    0.006708  0.000000  0.000000  0.006708  0.006708  0.006708    0.000000   \n",
       "1    0.000000  0.000000  0.008551  0.000000  0.000000  0.000000    0.008551   \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "3    0.000000  0.030516  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "5    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "\n",
       "       (mse  learning    images  ...  children    events     leave  \\\n",
       "0  0.006708  0.006708  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.005243  ...  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.007482  0.007482   \n",
       "3  0.000000  0.000000  0.000000  ...  0.015258  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.014033  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "   computers.  financial  fully-connected     whole   states,        76  \\\n",
       "0    0.000000   0.008226         0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.000000   0.000000         0.010486  0.000000  0.000000  0.000000   \n",
       "2    0.000000   0.004588         0.000000  0.000000  0.000000  0.000000   \n",
       "3    0.000000   0.000000         0.000000  0.000000  0.000000  0.000000   \n",
       "4    0.009264   0.000000         0.000000  0.009264  0.009264  0.009264   \n",
       "5    0.000000   0.000000         0.014033  0.000000  0.000000  0.000000   \n",
       "\n",
       "    exhaled  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.015258  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "\n",
       "[6 rows x 360 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tfidfDoc1, tfidfDoc2, tfidfDoc3, tfidfDoc4, tfidfDoc5, tfidfQuery])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89fe0b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006708200434341755, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.006708200434341755, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020124601303025267, 0.006708200434341755, 0.0, 0.0, 0.01341640086868351, 0.0, 0.0, 0.0, 0.0, 0.007785258508551237, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.004113114264824676, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.01341640086868351, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.01341640086868351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01341640086868351, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.006708200434341755, 0.0, 0.01341640086868351, 0.006708200434341755, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020124601303025267, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.03354100217170878, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.006708200434341755, 0.01341640086868351, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.01341640086868351, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.002595086169517079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01341640086868351, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.004113114264824676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002595086169517079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.007785258508551237, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.01341640086868351, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.006708200434341755, 0.004113114264824676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.02683280173736702, 0.006708200434341755, 0.006708200434341755, 0.01341640086868351, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006708200434341755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008226228529649353, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print (list(tfidfDoc1.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4469a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that spatial.distance.cosine computes the distance, and not the similarity. So, you must subtract the value from 1 to get the similarity.\n",
    "#result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "doc1_result = 1 - spatial.distance.cosine(list(tfidfDoc1.values()),list(tfidfQuery.values()))\n",
    "doc2_result = 1 - spatial.distance.cosine(list(tfidfDoc2.values()),list(tfidfQuery.values()))\n",
    "doc3_result = 1 - spatial.distance.cosine(list(tfidfDoc3.values()),list(tfidfQuery.values()))\n",
    "doc4_result = 1 - spatial.distance.cosine(list(tfidfDoc4.values()),list(tfidfQuery.values()))\n",
    "doc5_result = 1 - spatial.distance.cosine(list(tfidfDoc5.values()),list(tfidfQuery.values()))\n",
    "query_result = 1 - spatial.distance.cosine(list(tfidfQuery.values()),list(tfidfQuery.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "163bd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014825628629729803 0.428825481284952 0.0033553084743046524 0.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(doc1_result, doc2_result, doc3_result,doc4_result, doc5_result, query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eadbe3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document 2 is the most similar document to Query document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
